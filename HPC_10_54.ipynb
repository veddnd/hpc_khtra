{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK9pofipSB8V",
        "outputId": "28162ea7-bd99-442d-9052-b637e65394d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Oct 26 16:13:23 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "/usr/local/cuda/bin/nvcc\n",
            "nvcc is available\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "# Colab setup: check GPU and nvcc; try installing nvcc if it's missing.\n",
        "# Run in a code cell with `!` commands (Colab/python cell).\n",
        "# Copy-paste this into the first cell and run.\n",
        "\n",
        "# Show GPU details\n",
        "!nvidia-smi\n",
        "\n",
        "# Check nvcc\n",
        "!which nvcc || echo \"nvcc not found\"\n",
        "\n",
        "# If nvcc missing, install a lightweight package that provides nvcc\n",
        "# (this works in Colab's Ubuntu environment most of the time)\n",
        "import os,sys,subprocess,shlex\n",
        "rc = subprocess.call(\"which nvcc\", shell=True)\n",
        "if rc != 0:\n",
        "    print(\"nvcc not found â€” attempting to install nvidia-cuda-toolkit (may take a minute)...\")\n",
        "    # install package that usually contains nvcc\n",
        "    !apt-get update -qq\n",
        "    !DEBIAN_FRONTEND=noninteractive apt-get install -y -qq nvidia-cuda-toolkit\n",
        "    print(\"install attempted. Re-checking nvcc:\")\n",
        "    !which nvcc || echo \"nvcc still not found. If it's missing, try restarting the runtime and re-run this cell.\"\n",
        "else:\n",
        "    print(\"nvcc is available\")\n",
        "!nvcc --version || true\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile device_props.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int deviceCount;\n",
        "    cudaGetDeviceCount(&deviceCount);\n",
        "    if (deviceCount == 0)\n",
        "    {\n",
        "        printf(\"There is no device supporting CUDA\\n\");\n",
        "    }\n",
        "    int dev;\n",
        "    for (dev = 0; dev < deviceCount; ++dev)\n",
        "    {\n",
        "        cudaDeviceProp deviceProp;\n",
        "        cudaGetDeviceProperties(&deviceProp, dev);\n",
        "        if (dev == 0)\n",
        "        {\n",
        "            if (deviceProp.major < 1)\n",
        "            {\n",
        "                printf(\"There is no device supporting CUDA.\\n\");\n",
        "            }\n",
        "            else if (deviceCount == 1)\n",
        "            {\n",
        "                printf(\"There is 1 device supporting CUDA\\n\");\n",
        "            }\n",
        "            else\n",
        "            {\n",
        "                printf(\"There are %d devices supporting CUDA\\n\", deviceCount);\n",
        "            }\n",
        "        }\n",
        "        printf(\"\\nDevice %d: \\\"%s\\\"\\n\", dev, deviceProp.name);\n",
        "        printf(\"  Major revision number:                         %d\\n\", deviceProp.major);\n",
        "        printf(\"  Minor revision number:                         %d\\n\", deviceProp.minor);\n",
        "        printf(\"  Total amount of global memory:                 %zu bytes\\n\", (size_t)deviceProp.totalGlobalMem);\n",
        "        printf(\"  Total amount of constant memory:               %zu bytes\\n\", (size_t)deviceProp.totalConstMem);\n",
        "        printf(\"  Total amount of shared memory per block:       %zu bytes\\n\", (size_t)deviceProp.sharedMemPerBlock);\n",
        "        printf(\"  Total number of registers available per block: %d\\n\", deviceProp.regsPerBlock);\n",
        "        printf(\"  Warp size:                                     %d\\n\", deviceProp.warpSize);\n",
        "        printf(\"  Multiprocessor count:                          %d\\n\",deviceProp.multiProcessorCount );\n",
        "        printf(\"  Maximum number of threads per block:           %d\\n\", deviceProp.maxThreadsPerBlock);\n",
        "        printf(\"  Maximum sizes of each dimension of a block:    %d x %d x %d\\n\", deviceProp.maxThreadsDim[0],deviceProp.maxThreadsDim[1], deviceProp.maxThreadsDim[2]);\n",
        "        printf(\"  Maximum sizes of each dimension of a grid:     %d x %d x %d\\n\", deviceProp.maxGridSize[0], deviceProp.maxGridSize[1],  deviceProp.maxGridSize[2]);\n",
        "        printf(\"  Maximum memory pitch:                          %zu bytes\\n\", (size_t)deviceProp.memPitch);\n",
        "        printf(\"  Texture alignment:                             %zu bytes\\n\", (size_t)deviceProp.textureAlignment);\n",
        "        printf(\"  Clock rate:                                    %d kilohertz\\n\", deviceProp.clockRate);\n",
        "    }\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "!nvcc -arch=sm_50 -o device_props device_props.cu\n",
        "!./device_props\n"
      ],
      "metadata": {
        "id": "iNNf7N2MVQ_1",
        "outputId": "54b42d97-4729-4eb4-c404-ebf74ec6acbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting device_props.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm device_props.cu\n"
      ],
      "metadata": {
        "id": "vgWDY4LgTvVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile device_props.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int deviceCount;\n",
        "    cudaGetDeviceCount(&deviceCount);\n",
        "    if (deviceCount == 0)\n",
        "    {\n",
        "        printf(\"There is no device supporting CUDA\\n\");\n",
        "    }\n",
        "    int dev;\n",
        "    for (dev = 0; dev < deviceCount; ++dev)\n",
        "    {\n",
        "        cudaDeviceProp deviceProp;\n",
        "        cudaGetDeviceProperties(&deviceProp, dev);\n",
        "        if (dev == 0)\n",
        "        {\n",
        "            if (deviceProp.major < 1)\n",
        "            {\n",
        "                printf(\"There is no device supporting CUDA.\\n\");\n",
        "            }\n",
        "            else if (deviceCount == 1)\n",
        "            {\n",
        "                printf(\"There is 1 device supporting CUDA\\n\");\n",
        "            }\n",
        "            else\n",
        "            {\n",
        "                printf(\"There are %d devices supporting CUDA\\n\", deviceCount);\n",
        "            }\n",
        "        }\n",
        "        printf(\"\\nDevice %d: \\\"%s\\\"\\n\", dev, deviceProp.name);\n",
        "        printf(\"  Major revision number:                         %d\\n\", deviceProp.major);\n",
        "        printf(\"  Minor revision number:                         %d\\n\", deviceProp.minor);\n",
        "        printf(\"  Total amount of global memory:                 %zu bytes\\n\", (size_t)deviceProp.totalGlobalMem);\n",
        "        printf(\"  Total amount of constant memory:               %zu bytes\\n\", (size_t)deviceProp.totalConstMem);\n",
        "        printf(\"  Total amount of shared memory per block:       %zu bytes\\n\", (size_t)deviceProp.sharedMemPerBlock);\n",
        "        printf(\"  Total number of registers available per block: %d\\n\", deviceProp.regsPerBlock);\n",
        "        printf(\"  Warp size:                                     %d\\n\", deviceProp.warpSize);\n",
        "        printf(\"  Multiprocessor count:                          %d\\n\",deviceProp.multiProcessorCount );\n",
        "        printf(\"  Maximum number of threads per block:           %d\\n\", deviceProp.maxThreadsPerBlock);\n",
        "        printf(\"  Maximum sizes of each dimension of a block:    %d x %d x %d\\n\", deviceProp.maxThreadsDim[0],deviceProp.maxThreadsDim[1], deviceProp.maxThreadsDim[2]);\n",
        "        printf(\"  Maximum sizes of each dimension of a grid:     %d x %d x %d\\n\", deviceProp.maxGridSize[0], deviceProp.maxGridSize[1],  deviceProp.maxGridSize[2]);\n",
        "        printf(\"  Maximum memory pitch:                          %zu bytes\\n\", (size_t)deviceProp.memPitch);\n",
        "        printf(\"  Texture alignment:                             %zu bytes\\n\", (size_t)deviceProp.textureAlignment);\n",
        "        printf(\"  Clock rate:                                    %d kilohertz\\n\", deviceProp.clockRate);\n",
        "    }\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfuMOmhfSpXz",
        "outputId": "0dacad56-9222-4384-954e-215e42a5d422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing device_props.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_50 -o device_props device_props.cu\n",
        "!./device_props\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENz_Tw-oT4QX",
        "outputId": "244840ea-fbc2-41c6-8b37-da7d9435ae4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is 1 device supporting CUDA\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  Major revision number:                         7\n",
            "  Minor revision number:                         5\n",
            "  Total amount of global memory:                 15828320256 bytes\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Multiprocessor count:                          40\n",
            "  Maximum number of threads per block:           1024\n",
            "  Maximum sizes of each dimension of a block:    1024 x 1024 x 64\n",
            "  Maximum sizes of each dimension of a grid:     2147483647 x 65535 x 65535\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "  Texture alignment:                             512 bytes\n",
            "  Clock rate:                                    1590000 kilohertz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello_block1.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Kernel function executed by GPU threads\n",
        "__global__ void hello_kernel() {\n",
        "    int tid = threadIdx.x;  // thread ID within the block\n",
        "    printf(\"Hello World from thread %d (in block %d)\\\\n\", tid, blockIdx.x);\n",
        "}\n",
        "\n",
        "// Main function runs on CPU\n",
        "int main() {\n",
        "    int threadsPerBlock = 8; // you can change to 16, 32, etc.\n",
        "    printf(\"Launching kernel with 1 block and %d threads...\\\\n\", threadsPerBlock);\n",
        "\n",
        "    // Launch kernel <<<number_of_blocks, threads_per_block>>>\n",
        "    hello_kernel<<<1, threadsPerBlock>>>();\n",
        "\n",
        "    // Wait for all threads to finish before exiting\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLKJKd2nUK_A",
        "outputId": "0dcbb4cb-619d-4fc8-8970-44edc4ad5a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello_block1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_50 -o hello_block1 hello_block1.cu\n",
        "!./hello_block1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7xir_sbUMbl",
        "outputId": "6fa3aee2-10df-4994-8820-c13173605b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching kernel with 1 block and 8 threads...\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello_blocks_threads.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Kernel function executed by GPU threads\n",
        "__global__ void hello_kernel() {\n",
        "    int threadId = threadIdx.x;   // thread index inside the block\n",
        "    int blockId = blockIdx.x;     // block index\n",
        "    int globalId = blockId * blockDim.x + threadId; // overall thread ID\n",
        "\n",
        "    printf(\"Hello World from global thread %d (block %d, thread %d)\\\\n\",\n",
        "           globalId, blockId, threadId);\n",
        "}\n",
        "\n",
        "// Main function runs on CPU\n",
        "int main() {\n",
        "    int threadsPerBlock = 4;   // threads per block\n",
        "    int numBlocks = 3;         // number of blocks\n",
        "    printf(\"Launching kernel with %d blocks and %d threads per block...\\\\n\",\n",
        "           numBlocks, threadsPerBlock);\n",
        "\n",
        "    // Launch kernel\n",
        "    hello_kernel<<<numBlocks, threadsPerBlock>>>();\n",
        "\n",
        "    // Wait for all threads to finish\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_zN8GCJUrDW",
        "outputId": "6f333113-1ad2-4e82-8cdd-4eb6e0e98568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello_blocks_threads.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_50 -o hello_blocks_threads hello_blocks_threads.cu\n",
        "!./hello_blocks_threads\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6wrvwZBUvgF",
        "outputId": "92cd603e-d294-4be5-c299-9051c872f056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching kernel with 3 blocks and 4 threads per block...\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello_2d.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Kernel function executed by GPU threads\n",
        "__global__ void hello2D_kernel() {\n",
        "    int bx = blockIdx.x;  // Block index (x-dimension)\n",
        "    int by = blockIdx.y;  // Block index (y-dimension)\n",
        "    int tx = threadIdx.x; // Thread index within the block (x-dimension)\n",
        "    int ty = threadIdx.y; // Thread index within the block (y-dimension)\n",
        "\n",
        "    // Compute unique global coordinates for thread\n",
        "    printf(\"Hello World from block(%d,%d), thread(%d,%d)\\\\n\", bx, by, tx, ty);\n",
        "}\n",
        "\n",
        "// Main function runs on CPU\n",
        "int main() {\n",
        "    dim3 threadsPerBlock(4, 2);  // Each block has 4x2 = 8 threads\n",
        "    dim3 numBlocks(2, 2);        // Grid has 2x2 = 4 blocks\n",
        "    printf(\"Launching kernel with grid(%d,%d) blocks and block(%d,%d) threads...\\\\n\",\n",
        "           numBlocks.x, numBlocks.y, threadsPerBlock.x, threadsPerBlock.y);\n",
        "\n",
        "    // Launch the kernel with 2D configuration\n",
        "    hello2D_kernel<<<numBlocks, threadsPerBlock>>>();\n",
        "\n",
        "    // Wait for all threads to finish\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzYTLA4_VwVh",
        "outputId": "7adc537a-00c4-42ae-ed89-2a807365dee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello_2d.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_50 -o hello_2d hello_2d.cu\n",
        "!./hello_2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHZiKU35VymK",
        "outputId": "051d1cf7-9b89-4210-eab2-c8019b454d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching kernel with grid(2,2) blocks and block(4,2) threads...\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vec_add.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <chrono>  // for CPU timing\n",
        "\n",
        "// =========================\n",
        "// CUDA kernel for vector addition\n",
        "// =========================\n",
        "__global__ void vecAddKernel(const float *A, const float *B, float *C, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N)\n",
        "        C[i] = A[i] + B[i];\n",
        "}\n",
        "\n",
        "// Main program\n",
        "// =========================\n",
        "int main(int argc, char **argv) {\n",
        "    int N = 1000000; // default size = 10^6\n",
        "    if (argc > 1)\n",
        "        N = atoi(argv[1]);\n",
        "    printf(\"Vector Size: %d\\n\", N);\n",
        "\n",
        "    // Allocate host memory\n",
        "    float *h_A = (float *)malloc(N * sizeof(float));\n",
        "    float *h_B = (float *)malloc(N * sizeof(float));\n",
        "    float *h_C = (float *)malloc(N * sizeof(float));      // GPU result\n",
        "    float *h_C_ref = (float *)malloc(N * sizeof(float));  // CPU result\n",
        "\n",
        "    // Initialize input vectors with random values\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_A[i] = rand() / (float)RAND_MAX;\n",
        "        h_B[i] = rand() / (float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // =========================\n",
        "    // CPU (Serial) Computation\n",
        "    // =========================\n",
        "    auto cpu_start = std::chrono::high_resolution_clock::now();\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_C_ref[i] = h_A[i] + h_B[i];\n",
        "    }\n",
        "    auto cpu_end = std::chrono::high_resolution_clock::now();\n",
        "    double cpu_time = std::chrono::duration<double>(cpu_end - cpu_start).count();\n",
        "    printf(\"CPU time: %f seconds\\n\", cpu_time);\n",
        "\n",
        "    // =========================\n",
        "    // GPU (Parallel) Computation\n",
        "    // =========================\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void **)&d_A, N * sizeof(float));\n",
        "    cudaMalloc((void **)&d_B, N * sizeof(float));\n",
        "    cudaMalloc((void **)&d_C, N * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threads = 256;\n",
        "    int blocks = (N + threads - 1) / threads;\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    vecAddKernel<<<blocks, threads>>>(d_A, d_B, d_C, N);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float gpu_ms = 0;\n",
        "    cudaEventElapsedTime(&gpu_ms, start, stop); // milliseconds\n",
        "    double gpu_time = gpu_ms / 1000.0;\n",
        "\n",
        "    printf(\"GPU kernel time: %f ms (%f seconds)\\n\", gpu_ms, gpu_time);\n",
        "\n",
        "    // =========================\n",
        "    // Verification\n",
        "    // =========================\n",
        "    bool correct = true;\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        if (fabs(h_C[i] - h_C_ref[i]) > 1e-5) {\n",
        "            correct = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    printf(\"Verification: %s\\n\", correct ? \"PASS\" : \"FAIL\");\n",
        "\n",
        "    // =========================\n",
        "    // Speedup\n",
        "    // =========================\n",
        "    if (gpu_time > 0)\n",
        "        printf(\"Speedup (CPU/GPU): %f\\n\", cpu_time / gpu_time);\n",
        "\n",
        "    // Cleanup\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    free(h_C_ref);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5kEhQldXlVe",
        "outputId": "1aec2d1d-048d-4f27-82bb-13ec295c95a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vec_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "!nvcc -arch=sm_50 -O2 -o vec_add vec_add.cu\n",
        "\n",
        "# Run for different N values (10^5, 10^6, 10^7)\n",
        "!./vec_add 100000\n",
        "!./vec_add 1000000\n",
        "!./vec_add 5000000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn5igVU9Xqyk",
        "outputId": "9ad60348-242f-41ea-c3a2-32e1673be71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Size: 100000\n",
            "CPU time: 0.000229 seconds\n",
            "GPU kernel time: 7.349440 ms (0.007349 seconds)\n",
            "Verification: FAIL\n",
            "Speedup (CPU/GPU): 0.031094\n",
            "Vector Size: 1000000\n",
            "CPU time: 0.002322 seconds\n",
            "GPU kernel time: 7.301312 ms (0.007301 seconds)\n",
            "Verification: FAIL\n",
            "Speedup (CPU/GPU): 0.318015\n",
            "Vector Size: 5000000\n",
            "CPU time: 0.011441 seconds\n",
            "GPU kernel time: 7.097408 ms (0.007097 seconds)\n",
            "Verification: FAIL\n",
            "Speedup (CPU/GPU): 1.611938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_add.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <chrono> // for CPU timing\n",
        "\n",
        "// =============================\n",
        "// CUDA kernel for matrix addition\n",
        "// =============================\n",
        "__global__ void matrixAddKernel(float *A, float *B, float *C, int M, int N) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y; // row index\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x; // column index\n",
        "    int index = row * N + col; // linear index\n",
        "\n",
        "    if (row < M && col < N) {\n",
        "        C[index] = A[index] + B[index];\n",
        "    }\n",
        "}\n",
        "\n",
        "// =============================\n",
        "// Main program\n",
        "// =============================\n",
        "int main(int argc, char **argv) {\n",
        "    int M = 1000, N = 1000; // Default matrix size\n",
        "    if (argc == 3) {\n",
        "        M = atoi(argv[1]);\n",
        "        N = atoi(argv[2]);\n",
        "    }\n",
        "    printf(\"Matrix size: %d x %d\\n\", M, N);\n",
        "\n",
        "    int size = M * N * sizeof(float);\n",
        "\n",
        "    // Host memory allocation\n",
        "    float *h_A = (float *)malloc(size);\n",
        "    float *h_B = (float *)malloc(size);\n",
        "    float *h_C = (float *)malloc(size);      // GPU result\n",
        "    float *h_C_ref = (float *)malloc(size);  // CPU result\n",
        "\n",
        "    // Initialize input matrices with random values\n",
        "    for (int i = 0; i < M * N; i++) {\n",
        "        h_A[i] = rand() / (float)RAND_MAX;\n",
        "        h_B[i] = rand() / (float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // =============================\n",
        "    // CPU (Serial) computation\n",
        "    // =============================\n",
        "    auto cpu_start = std::chrono::high_resolution_clock::now();\n",
        "    for (int i = 0; i < M; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            h_C_ref[i * N + j] = h_A[i * N + j] + h_B[i * N + j];\n",
        "        }\n",
        "    }\n",
        "    auto cpu_end = std::chrono::high_resolution_clock::now();\n",
        "    double cpu_time = std::chrono::duration<double>(cpu_end - cpu_start).count();\n",
        "    printf(\"CPU time: %f seconds\\n\", cpu_time);\n",
        "\n",
        "    // =============================\n",
        "    // GPU (Parallel) computation\n",
        "    // =============================\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, size);\n",
        "    cudaMalloc(&d_B, size);\n",
        "    cudaMalloc(&d_C, size);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 numBlocks((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
        "                   (M + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    matrixAddKernel<<<numBlocks, threadsPerBlock>>>(d_A, d_B, d_C, M, N);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float gpu_ms = 0;\n",
        "    cudaEventElapsedTime(&gpu_ms, start, stop);\n",
        "    double gpu_time = gpu_ms / 1000.0;\n",
        "\n",
        "    printf(\"GPU time: %f ms (%f seconds)\\n\", gpu_ms, gpu_time);\n",
        "\n",
        "    // =============================\n",
        "    // Verification\n",
        "    // =============================\n",
        "    bool correct = true;\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        if (fabs(h_C[i] - h_C_ref[i]) > 1e-5) {\n",
        "            correct = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    printf(\"Verification: %s\\n\", correct ? \"PASS\" : \"FAIL\");\n",
        "\n",
        "    // =============================\n",
        "    // Speedup\n",
        "    // =============================\n",
        "    if (gpu_time > 0)\n",
        "        printf(\"Speedup (CPU/GPU): %f\\n\", cpu_time / gpu_time);\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    free(h_C_ref);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCIFMzukYzUY",
        "outputId": "1b9c0d69-2536-4732-c617-389d87937543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "!nvcc -arch=sm_50 -O2 -o matrix_add matrix_add.cu\n",
        "\n",
        "# Run for different matrix sizes\n",
        "!./matrix_add 100 100\n",
        "!./matrix_add 500 500\n",
        "!./matrix_add 1000 1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hU4c_ZPY3gu",
        "outputId": "7270d465-4637-4fce-a5da-16b9f6996b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix size: 100 x 100\n",
            "CPU time: 0.000030 seconds\n",
            "GPU time: 7.523808 ms (0.007524 seconds)\n",
            "Verification: FAIL\n",
            "Speedup (CPU/GPU): 0.004035\n",
            "Matrix size: 500 x 500\n",
            "CPU time: 0.000583 seconds\n",
            "GPU time: 7.118336 ms (0.007118 seconds)\n",
            "Verification: FAIL\n",
            "Speedup (CPU/GPU): 0.081934\n",
            "Matrix size: 1000 x 1000\n",
            "CPU time: 0.003076 seconds\n",
            "GPU time: 10.753696 ms (0.010754 seconds)\n",
            "Verification: FAIL\n",
            "Speedup (CPU/GPU): 0.286059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_dot.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <chrono>\n",
        "#include <math.h>\n",
        "\n",
        "// =============================\n",
        "// CUDA kernel for dot product\n",
        "// =============================\n",
        "__global__ void dotProductKernel(float *A, float *B, float *partial_sum, int N) {\n",
        "    __shared__ float cache[256]; // Shared memory for reduction\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int cacheIndex = threadIdx.x;\n",
        "\n",
        "    float temp = 0;\n",
        "    while (tid < N) {\n",
        "        temp += A[tid] * B[tid];\n",
        "        tid += blockDim.x * gridDim.x;\n",
        "    }\n",
        "\n",
        "    cache[cacheIndex] = temp;\n",
        "    __syncthreads();\n",
        "\n",
        "    // Reduction in shared memory\n",
        "    int i = blockDim.x / 2;\n",
        "    while (i != 0) {\n",
        "        if (cacheIndex < i)\n",
        "            cache[cacheIndex] += cache[cacheIndex + i];\n",
        "        __syncthreads();\n",
        "        i /= 2;\n",
        "    }\n",
        "\n",
        "    if (cacheIndex == 0)\n",
        "        partial_sum[blockIdx.x] = cache[0];\n",
        "}\n",
        "\n",
        "// =============================\n",
        "// Main program\n",
        "// =============================\n",
        "int main(int argc, char **argv) {\n",
        "    int N = 1000000; // Default vector size\n",
        "    if (argc == 2)\n",
        "        N = atoi(argv[1]);\n",
        "    printf(\"Vector size: %d\\n\", N);\n",
        "\n",
        "    int size = N * sizeof(float);\n",
        "\n",
        "    // Host memory allocation\n",
        "    float *h_A = (float *)malloc(size);\n",
        "    float *h_B = (float *)malloc(size);\n",
        "    float *h_partial = (float *)malloc(256 * sizeof(float)); // for GPU partial sums\n",
        "\n",
        "    // Initialize vectors\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_A[i] = rand() / (float)RAND_MAX;\n",
        "        h_B[i] = rand() / (float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // =============================\n",
        "    // CPU (Serial) computation\n",
        "    // =============================\n",
        "    auto cpu_start = std::chrono::high_resolution_clock::now();\n",
        "    float cpu_result = 0;\n",
        "    for (int i = 0; i < N; i++)\n",
        "        cpu_result += h_A[i] * h_B[i];\n",
        "    auto cpu_end = std::chrono::high_resolution_clock::now();\n",
        "    double cpu_time = std::chrono::duration<double>(cpu_end - cpu_start).count();\n",
        "    printf(\"CPU Dot Product: %f\\n\", cpu_result);\n",
        "    printf(\"CPU time: %f seconds\\n\", cpu_time);\n",
        "\n",
        "    // =============================\n",
        "    // GPU (Parallel) computation\n",
        "    // =============================\n",
        "    float *d_A, *d_B, *d_partial;\n",
        "    cudaMalloc(&d_A, size);\n",
        "    cudaMalloc(&d_B, size);\n",
        "    int blocks = 256;\n",
        "    cudaMalloc(&d_partial, blocks * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    dotProductKernel<<<blocks, 256>>>(d_A, d_B, d_partial, N);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    cudaMemcpy(h_partial, d_partial, blocks * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float gpu_result = 0;\n",
        "    for (int i = 0; i < blocks; i++)\n",
        "        gpu_result += h_partial[i];\n",
        "\n",
        "    float gpu_ms = 0;\n",
        "    cudaEventElapsedTime(&gpu_ms, start, stop);\n",
        "    double gpu_time = gpu_ms / 1000.0;\n",
        "\n",
        "    printf(\"GPU Dot Product: %f\\n\", gpu_result);\n",
        "    printf(\"GPU time: %f ms (%f seconds)\\n\", gpu_ms, gpu_time);\n",
        "\n",
        "    // =============================\n",
        "    // Verification\n",
        "    // =============================\n",
        "    bool correct = fabs(cpu_result - gpu_result) < 1e-5;\n",
        "    printf(\"Verification: %s\\n\", correct ? \"PASS\" : \"FAIL\");\n",
        "\n",
        "    // =============================\n",
        "    // Speedup\n",
        "    // =============================\n",
        "    if (gpu_time > 0)\n",
        "        printf(\"Speedup (CPU/GPU): %f\\n\", cpu_time / gpu_time);\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_partial);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_partial);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yRgdyF1ZSQE",
        "outputId": "45a44cb5-af4a-4318-feef-a3d6cf99e5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_dot.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile CUDA program\n",
        "!nvcc -arch=sm_50 -O2 -o vector_dot vector_dot.cu\n",
        "\n",
        "# Run for different vector sizes\n",
        "!./vector_dot 100000      # 1e5\n",
        "!./vector_dot 1000000     # 1e6\n",
        "!./vector_dot 10000000    # 1e7\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv0aBtQKaBIZ",
        "outputId": "e85a2cf7-0a06-47e4-f249-dd9067f51def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector size: 100000\n",
            "CPU Dot Product: 25001.640625\n",
            "CPU time: 0.000130 seconds\n",
            "GPU Dot Product: 0.000000\n",
            "GPU time: 7.519104 ms (0.007519 seconds)\n",
            "Verification: FAIL\n",
            "Speedup (CPU/GPU): 0.017308\n",
            "Vector size: 1000000\n",
            "CPU Dot Product: 250005.875000\n",
            "CPU time: 0.001337 seconds\n",
            "GPU Dot Product: 0.000000\n",
            "GPU time: 7.243040 ms (0.007243 seconds)\n",
            "Verification: FAIL\n",
            "Speedup (CPU/GPU): 0.184546\n",
            "Vector size: 10000000\n",
            "CPU Dot Product: 2471362.250000\n",
            "CPU time: 0.013352 seconds\n",
            "GPU Dot Product: 0.000000\n",
            "GPU time: 7.881728 ms (0.007882 seconds)\n",
            "Verification: FAIL\n",
            "Speedup (CPU/GPU): 1.694043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <chrono>\n",
        "#include <math.h>\n",
        "\n",
        "// =============================\n",
        "// CUDA kernel for matrix multiplication\n",
        "// =============================\n",
        "__global__ void matrixMulKernel(float *A, float *B, float *C, int M, int N, int P) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < M && col < P) {\n",
        "        float sum = 0;\n",
        "        for (int k = 0; k < N; k++) {\n",
        "            sum += A[row * N + k] * B[k * P + col];\n",
        "        }\n",
        "        C[row * P + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// =============================\n",
        "// Main program\n",
        "// =============================\n",
        "int main(int argc, char **argv) {\n",
        "    int M = 100, N = 100, P = 100; // Default sizes\n",
        "    if (argc == 4) {\n",
        "        M = atoi(argv[1]);\n",
        "        N = atoi(argv[2]);\n",
        "        P = atoi(argv[3]);\n",
        "    }\n",
        "    printf(\"Matrix sizes: A(%dx%d), B(%dx%d)\\n\", M, N, N, P);\n",
        "\n",
        "    int size_A = M * N * sizeof(float);\n",
        "    int size_B = N * P * sizeof(float);\n",
        "    int size_C = M * P * sizeof(float);\n",
        "\n",
        "    // Host memory allocation\n",
        "    float *h_A = (float*)malloc(size_A);\n",
        "    float *h_B = (float*)malloc(size_B);\n",
        "    float *h_C = (float*)malloc(size_C);      // GPU result\n",
        "    float *h_C_ref = (float*)malloc(size_C);  // CPU result\n",
        "\n",
        "    // Initialize matrices with random values\n",
        "    for (int i = 0; i < M * N; i++) h_A[i] = rand() / (float)RAND_MAX;\n",
        "    for (int i = 0; i < N * P; i++) h_B[i] = rand() / (float)RAND_MAX;\n",
        "\n",
        "    // =============================\n",
        "    // CPU (Serial) computation\n",
        "    // =============================\n",
        "    auto cpu_start = std::chrono::high_resolution_clock::now();\n",
        "    for (int i = 0; i < M; i++) {\n",
        "        for (int j = 0; j < P; j++) {\n",
        "            float sum = 0;\n",
        "            for (int k = 0; k < N; k++) {\n",
        "                sum += h_A[i * N + k] * h_B[k * P + j];\n",
        "            }\n",
        "            h_C_ref[i * P + j] = sum;\n",
        "        }\n",
        "    }\n",
        "    auto cpu_end = std::chrono::high_resolution_clock::now();\n",
        "    double cpu_time = std::chrono::duration<double>(cpu_end - cpu_start).count();\n",
        "    printf(\"CPU time: %f seconds\\n\", cpu_time);\n",
        "\n",
        "    // =============================\n",
        "    // GPU (Parallel) computation\n",
        "    // =============================\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, size_A);\n",
        "    cudaMalloc(&d_B, size_B);\n",
        "    cudaMalloc(&d_C, size_C);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size_A, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size_B, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 numBlocks((P + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
        "                   (M + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    matrixMulKernel<<<numBlocks, threadsPerBlock>>>(d_A, d_B, d_C, M, N, P);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, size_C, cudaMemcpyDeviceToHost);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float gpu_ms = 0;\n",
        "    cudaEventElapsedTime(&gpu_ms, start, stop);\n",
        "    double gpu_time = gpu_ms / 1000.0;\n",
        "    printf(\"GPU time: %f ms (%f seconds)\\n\", gpu_ms, gpu_time);\n",
        "\n",
        "    // =============================\n",
        "    // Verification\n",
        "    // =============================\n",
        "    bool correct = true;\n",
        "    for (int i = 0; i < M * P; i++) {\n",
        "        if (fabs(h_C[i] - h_C_ref[i]) > 1e-4) {\n",
        "            correct = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    printf(\"Verification: %s\\n\", correct ? \"PASS\" : \"FAIL\");\n",
        "\n",
        "    // =============================\n",
        "    // Speedup\n",
        "    // =============================\n",
        "    if (gpu_time > 0)\n",
        "        printf(\"Speedup (CPU/GPU): %f\\n\", cpu_time / gpu_time);\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    free(h_C_ref);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "_p4VKpRpaszT",
        "outputId": "a793e7a5-117e-40e9-df6f-ef030efbf8dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "!nvcc -arch=sm_50 -O2 -o matrix_mul matrix_mul.cu\n",
        "\n",
        "# Run for different sizes\n",
        "!./matrix_mul 100 100 100\n",
        "!./matrix_mul 500 500 500\n",
        "!./matrix_mul 1000 1000 1000\n"
      ],
      "metadata": {
        "id": "C6GjRwedavaG",
        "outputId": "ece40663-0dbf-4516-aa69-b541b5bdc71d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix sizes: A(100x100), B(100x100)\n",
            "CPU time: 0.001036 seconds\n",
            "GPU time: 7.718336 ms (0.007718 seconds)\n",
            "Verification: FAIL\n",
            "Speedup (CPU/GPU): 0.134186\n",
            "Matrix sizes: A(500x500), B(500x500)\n",
            "CPU time: 0.159607 seconds\n",
            "GPU time: 7.337952 ms (0.007338 seconds)\n",
            "Verification: FAIL\n",
            "Speedup (CPU/GPU): 21.750851\n",
            "Matrix sizes: A(1000x1000), B(1000x1000)\n",
            "CPU time: 1.307361 seconds\n",
            "GPU time: 7.192192 ms (0.007192 seconds)\n",
            "Verification: FAIL\n",
            "Speedup (CPU/GPU): 181.774990\n"
          ]
        }
      ]
    }
  ]
}